import 'dart:io';
import 'dart:convert';
import 'dart:typed_data';
import 'package:flutter/foundation.dart';
import 'package:flutter/services.dart';
import 'package:path_provider/path_provider.dart';
import 'package:dio/dio.dart';
import '../config/environment_config.dart';
import 'local_ai_model_manager.dart';
import 'local_ai_inference_engine.dart';

class OfflineAIService {
  static final OfflineAIService _instance = OfflineAIService._internal();
  factory OfflineAIService() => _instance;
  OfflineAIService._internal();

  // æœ¬åœ°AIç»„ä»¶
  final LocalAIModelManager _modelManager = LocalAIModelManager();
  final LocalAIInferenceEngine _inferenceEngine = LocalAIInferenceEngine();

  bool _isInitialized = false;
  String? _currentModelId;
  
  // æ¨¡å‹çŠ¶æ€
  bool get isInitialized => _isInitialized;
  String? get currentModelId => _currentModelId;
  bool get hasLoadedModel => _inferenceEngine.currentModelId != null;

  /// åˆå§‹åŒ–ç¦»çº¿AIæœåŠ¡
  Future<bool> initialize({String modelType = 'general'}) async {
    try {
      if (kIsWeb) {
        debugPrint('Webå¹³å°ä¸æ”¯æŒç¦»çº¿AIæ¨¡å‹');
        return false;
      }

      // åˆå§‹åŒ–æ¨ç†å¼•æ“
      if (!await _inferenceEngine.initialize()) {
        debugPrint('æ¨ç†å¼•æ“åˆå§‹åŒ–å¤±è´¥');
        return false;
      }

      // è·å–æ¨èçš„æ¨¡å‹ID
      final recommendedModelId = _getRecommendedModelForType(modelType);
      
      // æ£€æŸ¥æ¨èæ¨¡å‹æ˜¯å¦å·²ä¸‹è½½
      if (await _modelManager.isModelDownloaded(recommendedModelId)) {
        // åŠ è½½æ¨¡å‹
        if (await _inferenceEngine.loadModel(recommendedModelId)) {
          _currentModelId = recommendedModelId;
          _isInitialized = true;
          debugPrint('ç¦»çº¿AIæ¨¡å‹åˆå§‹åŒ–æˆåŠŸ: $recommendedModelId');
          return true;
        }
      }

      // å¦‚æœæ¨èæ¨¡å‹ä¸å¯ç”¨ï¼Œå°è¯•ä»»ä½•å·²ä¸‹è½½çš„æ¨¡å‹
      final downloadedModels = await _modelManager.getDownloadedModels();
      if (downloadedModels.isNotEmpty) {
        final firstModel = downloadedModels.first;
        if (await _inferenceEngine.loadModel(firstModel)) {
          _currentModelId = firstModel;
          _isInitialized = true;
          debugPrint('ç¦»çº¿AIä½¿ç”¨å·²æœ‰æ¨¡å‹: $firstModel');
          return true;
        }
      }

      debugPrint('æ²¡æœ‰å¯ç”¨çš„ç¦»çº¿AIæ¨¡å‹ï¼Œéœ€è¦å…ˆä¸‹è½½');
      return false;
    } catch (e) {
      debugPrint('ç¦»çº¿AIåˆå§‹åŒ–å¤±è´¥: $e');
      return false;
    }
  }

  /// ä¸‹è½½AIæ¨¡å‹
  Future<bool> downloadModel({
    required String modelType,
    required Function(double progress) onProgress,
    required Function() onSuccess,
    required Function(String error) onError,
  }) async {
    try {
      if (kIsWeb) {
        onError('Webå¹³å°ä¸æ”¯æŒç¦»çº¿æ¨¡å‹ä¸‹è½½');
        return false;
      }

      // è·å–æ¨èçš„æ¨¡å‹ID
      final modelId = _getRecommendedModelForType(modelType);
      
      debugPrint('å¼€å§‹ä¸‹è½½æ¨¡å‹: $modelId');

      // ä½¿ç”¨æ¨¡å‹ç®¡ç†å™¨ä¸‹è½½æ¨¡å‹
      await _modelManager.downloadModel(
        modelId,
        onProgress: onProgress,
        onSuccess: () async {
          debugPrint('æ¨¡å‹ä¸‹è½½å®Œæˆï¼Œå°è¯•åŠ è½½...');
          
          // ä¸‹è½½å®Œæˆåå°è¯•åŠ è½½æ¨¡å‹
          if (await _inferenceEngine.loadModel(modelId)) {
            _currentModelId = modelId;
            _isInitialized = true;
            debugPrint('æ¨¡å‹åŠ è½½æˆåŠŸ: $modelId');
            onSuccess();
          } else {
            onError('æ¨¡å‹ä¸‹è½½æˆåŠŸä½†åŠ è½½å¤±è´¥');
          }
        },
        onError: onError,
      );

      return true;
    } catch (e) {
      debugPrint('ä¸‹è½½æ¨¡å‹å¤±è´¥: $e');
      onError('ä¸‹è½½æ¨¡å‹å¤±è´¥: $e');
      return false;
    }
  }

  /// ç”Ÿæˆæ•™æ¡ˆï¼ˆç¦»çº¿æ¨¡å¼ï¼‰
  Future<String> generateLessonPlan({
    required String subject,
    required String grade,
    required String topic,
    String? requirements,
  }) async {
    if (!_isInitialized || !hasLoadedModel) {
      throw Exception('ğŸ˜Š ç¦»çº¿AIæ¨¡å‹æœªå‡†å¤‡å¥½\n\nğŸ’¡ è¯·å…ˆä¸‹è½½å¹¶åŠ è½½AIæ¨¡å‹ï¼š\n1. è¿›å…¥è®¾ç½®é¡µé¢\n2. ä¸‹è½½é€‚åˆçš„AIæ¨¡å‹\n3. ç­‰å¾…æ¨¡å‹åŠ è½½å®Œæˆ');
    }

    try {
      debugPrint('ä½¿ç”¨ç¦»çº¿AIç”Ÿæˆæ•™æ¡ˆ: $subject - $grade - $topic');
      
      final result = await _inferenceEngine.generateLessonPlan(
        subject: subject,
        grade: grade,
        topic: topic,
        requirements: requirements,
      );

      debugPrint('ç¦»çº¿æ•™æ¡ˆç”Ÿæˆå®Œæˆ');
      return result;
    } catch (e) {
      debugPrint('ç¦»çº¿ç”Ÿæˆæ•™æ¡ˆå¤±è´¥: $e');
      throw Exception('ğŸ˜… ç¦»çº¿æ•™æ¡ˆç”Ÿæˆé‡åˆ°é—®é¢˜\n\nğŸ’¡ å¯èƒ½çš„åŸå› ï¼š\n1. æ¨¡å‹è¿è¡Œå¼‚å¸¸\n2. è®¾å¤‡å†…å­˜ä¸è¶³\n3. è¯·å°è¯•é‡å¯åº”ç”¨');
    }
  }

  /// ç”Ÿæˆç»ƒä¹ é¢˜ï¼ˆç¦»çº¿æ¨¡å¼ï¼‰
  Future<String> generateExercises({
    required String subject,
    required String grade,
    required String topic,
    required String difficulty,
    required int count,
  }) async {
    if (!_isInitialized || !hasLoadedModel) {
      throw Exception('ğŸ˜Š ç¦»çº¿AIæ¨¡å‹æœªå‡†å¤‡å¥½ï¼Œè¯·å…ˆä¸‹è½½å¹¶åŠ è½½AIæ¨¡å‹');
    }

    try {
      debugPrint('ä½¿ç”¨ç¦»çº¿AIç”Ÿæˆç»ƒä¹ é¢˜: $subject - $grade - $topic');
      
      final result = await _inferenceEngine.generateExercises(
        subject: subject,
        grade: grade,
        topic: topic,
        difficulty: difficulty,
        count: count,
      );

      debugPrint('ç¦»çº¿ç»ƒä¹ é¢˜ç”Ÿæˆå®Œæˆ');
      return result;
    } catch (e) {
      debugPrint('ç¦»çº¿ç”Ÿæˆç»ƒä¹ é¢˜å¤±è´¥: $e');
      throw Exception('ğŸ˜… ç¦»çº¿ç»ƒä¹ é¢˜ç”Ÿæˆé‡åˆ°é—®é¢˜ï¼Œè¯·é‡è¯•æˆ–ä½¿ç”¨åœ¨çº¿æœåŠ¡');
    }
  }

  /// åˆ†æå†…å®¹ï¼ˆç¦»çº¿æ¨¡å¼ï¼‰
  Future<String> analyzeContent({
    required String content,
    required String analysisType,
  }) async {
    if (!_isInitialized || !hasLoadedModel) {
      return 'ğŸ˜Š ç¦»çº¿AIæ¨¡å‹æœªå‡†å¤‡å¥½ï¼Œè¯·å…ˆä¸‹è½½å¹¶åŠ è½½AIæ¨¡å‹';
    }

    try {
      debugPrint('ä½¿ç”¨ç¦»çº¿AIåˆ†æå†…å®¹: $analysisType');
      
      final result = await _inferenceEngine.analyzeContent(
        content: content,
        analysisType: analysisType,
      );

      debugPrint('ç¦»çº¿å†…å®¹åˆ†æå®Œæˆ');
      return result;
    } catch (e) {
      debugPrint('ç¦»çº¿å†…å®¹åˆ†æå¤±è´¥: $e');
      return 'ğŸ˜… å†…å®¹åˆ†ææš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•';
    }
  }

  /// è·å–æ¨¡å‹ä¿¡æ¯
  Map<String, dynamic> getModelInfo() {
    final currentModel = _currentModelId != null 
        ? _modelManager.getModelInfo(_currentModelId!)
        : null;
    
    return {
      'æœåŠ¡çŠ¶æ€': _isInitialized ? 'å·²åˆå§‹åŒ–' : 'æœªåˆå§‹åŒ–',
      'å½“å‰æ¨¡å‹': currentModel?.name ?? 'æ— ',
      'æ¨¡å‹ID': _currentModelId ?? 'æ— ',
      'æ¨ç†å¼•æ“': _inferenceEngine.isInitialized ? 'å°±ç»ª' : 'æœªå°±ç»ª',
      'æ”¯æŒçš„æ¨¡å‹': LocalAIModelManager.availableModels.keys.toList(),
    };
  }

  /// æ£€æŸ¥æ¨¡å‹å¯ç”¨æ€§
  Future<Map<String, bool>> checkModelsAvailability() async {
    if (kIsWeb) {
      return {'web': false}; // Webå¹³å°ä¸æ”¯æŒç¦»çº¿æ¨¡å‹
    }
    
    final availability = <String, bool>{};
    
    for (final modelId in LocalAIModelManager.availableModels.keys) {
      final isDownloaded = await _modelManager.isModelDownloaded(modelId);
      final isCompatible = await _modelManager.isDeviceCompatible(modelId);
      availability[modelId] = isDownloaded && isCompatible;
    }
    
    return availability;
  }

  /// è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨
  Future<List<ModelConfig>> getAvailableModels() async {
    return _modelManager.getAllAvailableModels();
  }

  /// è·å–å·²ä¸‹è½½çš„æ¨¡å‹åˆ—è¡¨
  Future<List<String>> getDownloadedModels() async {
    return _modelManager.getDownloadedModels();
  }

  /// åˆ é™¤æ¨¡å‹
  Future<bool> deleteModel(String modelId) async {
    try {
      // å¦‚æœæ˜¯å½“å‰ä½¿ç”¨çš„æ¨¡å‹ï¼Œå…ˆå¸è½½
      if (_currentModelId == modelId) {
        await _inferenceEngine.unloadModel();
        _currentModelId = null;
        _isInitialized = false;
      }

      return await _modelManager.deleteModel(modelId);
    } catch (e) {
      debugPrint('åˆ é™¤æ¨¡å‹å¤±è´¥: $e');
      return false;
    }
  }

  /// åˆ‡æ¢æ¨¡å‹
  Future<bool> switchModel(String modelId) async {
    try {
      if (!await _modelManager.isModelDownloaded(modelId)) {
        debugPrint('æ¨¡å‹æœªä¸‹è½½: $modelId');
        return false;
      }

      // å¸è½½å½“å‰æ¨¡å‹
      await _inferenceEngine.unloadModel();

      // åŠ è½½æ–°æ¨¡å‹
      if (await _inferenceEngine.loadModel(modelId)) {
        _currentModelId = modelId;
        _isInitialized = true;
        debugPrint('æˆåŠŸåˆ‡æ¢åˆ°æ¨¡å‹: $modelId');
        return true;
      } else {
        debugPrint('æ¨¡å‹åŠ è½½å¤±è´¥: $modelId');
        return false;
      }
    } catch (e) {
      debugPrint('åˆ‡æ¢æ¨¡å‹å¤±è´¥: $e');
      return false;
    }
  }

  /// è·å–è®¾å¤‡å…¼å®¹æ€§ä¿¡æ¯
  Future<Map<String, bool>> getDeviceCompatibility() async {
    final compatibility = <String, bool>{};
    
    for (final modelId in LocalAIModelManager.availableModels.keys) {
      compatibility[modelId] = await _modelManager.isDeviceCompatible(modelId);
    }
    
    return compatibility;
  }

  /// æ ¹æ®æ¨¡å‹ç±»å‹è·å–æ¨èçš„æ¨¡å‹ID
  String _getRecommendedModelForType(String modelType) {
    switch (modelType) {
      case 'education':
      case 'general':
        return 'education-lite-1b'; // è½»é‡çº§æ•™è‚²æ¨¡å‹ï¼Œé€‚åˆä¸­ä½ç«¯è®¾å¤‡
      case 'advanced':
        return 'qwen-1.8b-chat-int4'; // æ›´å¼ºå¤§çš„æ¨¡å‹ï¼Œéœ€è¦æ›´å¥½çš„è®¾å¤‡
      case 'premium':
        return 'chatglm3-6b-int4'; // æœ€å¼ºå¤§çš„æ¨¡å‹ï¼Œéœ€è¦é«˜ç«¯è®¾å¤‡
      default:
        return 'education-lite-1b';
    }
  }

  /// é‡Šæ”¾èµ„æº
  Future<void> dispose() async {
    try {
      await _inferenceEngine.dispose();
      _isInitialized = false;
      _currentModelId = null;
      debugPrint('ç¦»çº¿AIæœåŠ¡å·²é‡Šæ”¾èµ„æº');
    } catch (e) {
      debugPrint('é‡Šæ”¾ç¦»çº¿AIèµ„æºå¤±è´¥: $e');
    }
  }
} 