# Complete Self-Hosted TeachAI RAG System
# Includes: RAG data, embedding models, vector database, full stack
# Optimized for: 4-core CPU, 8GB RAM, 100GB storage

# Stage 1: Base with system dependencies
FROM node:18-alpine AS base
LABEL maintainer="TeachAI Team"
LABEL description="Complete self-hosted TeachAI RAG system"

# Install system dependencies for embedding models and SQLite
RUN apk update && apk add --no-cache \
    sqlite sqlite-dev \
    python3 py3-pip \
    make g++ git curl \
    ca-certificates \
    libc6-compat \
    && rm -rf /var/cache/apk/*

# Install Python dependencies for embedding models
RUN pip3 install --no-cache-dir \
    sentence-transformers==2.2.2 \
    torch==2.0.1+cpu \
    torchvision==0.15.2+cpu \
    -f https://download.pytorch.org/whl/cpu/torch_stable.html

# Install pnpm
RUN npm install -g pnpm@8

WORKDIR /app

# Stage 2: Install Node.js dependencies
FROM base AS deps
COPY pnpm-workspace.yaml package.json pnpm-lock.yaml ./
COPY web/package.json ./web/package.json
COPY server/package.json ./server/package.json

# Install dependencies with native compilation support
RUN pnpm install --frozen-lockfile --prod || pnpm install --force --prod

# Add additional dependencies for complete RAG system
RUN pnpm add -w \
    sqlite3@5.1.6 \
    @xenova/transformers@2.17.2 \
    onnxruntime-node@1.16.0 \
    lru-cache@10.0.0 \
    pako@2.1.0

# Stage 3: Build frontend
FROM base AS web-builder
COPY --from=deps /app/node_modules ./node_modules
COPY --from=deps /app/web/node_modules ./web/node_modules
COPY web ./web
COPY package.json pnpm-workspace.yaml ./

WORKDIR /app/web
ENV NODE_ENV=production
ENV NEXT_TELEMETRY_DISABLED=1
RUN pnpm build

# Stage 4: Prepare server and RAG system
FROM base AS server-builder
COPY --from=deps /app/node_modules ./node_modules
COPY --from=deps /app/server/node_modules ./server/node_modules
COPY server ./server
COPY package.json pnpm-workspace.yaml ./

# Copy simplified RAG system
COPY server/simple-rag/ ./server/simple-rag/

# Stage 5: Download and prepare embedding models
FROM python:3.11-slim AS model-downloader

# Install minimal dependencies
RUN pip install --no-cache-dir \
    sentence-transformers==2.2.2 \
    huggingface_hub

# Download embedding models to cache
RUN python -c "\
from sentence_transformers import SentenceTransformer; \
import os; \
os.makedirs('/models', exist_ok=True); \
models = {'ultra-lite': 'all-MiniLM-L6-v2', 'balanced': 'paraphrase-multilingual-MiniLM-L12-v2', 'quality': 'paraphrase-multilingual-mpnet-base-v2'}; \
[SentenceTransformer(model_name, cache_folder='/models').save(f'/models/{profile}') or print(f'Downloaded {profile} model: {model_name}') for profile, model_name in models.items()]"

# Stage 6: Production runtime with everything included
FROM node:18-alpine AS runner
LABEL version="2.0-complete-self-hosted"

# Install runtime dependencies
RUN apk add --no-cache \
    sqlite curl \
    python3 py3-pip \
    ca-certificates \
    && rm -rf /var/cache/apk/*

# Install Python runtime for embeddings
RUN pip3 install --no-cache-dir \
    sentence-transformers==2.2.2 \
    torch==2.0.1+cpu \
    -f https://download.pytorch.org/whl/cpu/torch_stable.html

# Create non-root user
RUN addgroup -g 1001 -S teachai && \
    adduser -S teachai -u 1001

WORKDIR /app

# Copy built applications
COPY --from=web-builder --chown=teachai:teachai /app/web/.next ./web/.next
COPY --from=web-builder --chown=teachai:teachai /app/web/public ./web/public
COPY --from=web-builder --chown=teachai:teachai /app/web/package.json ./web/package.json
COPY --from=web-builder /app/web/next.config.js ./web/next.config.js

COPY --from=server-builder --chown=teachai:teachai /app/server ./server
COPY --from=deps /app/node_modules ./node_modules
COPY --from=deps /app/web/node_modules ./web/node_modules
COPY --from=deps /app/server/node_modules ./server/node_modules

# Copy pre-trained embedding models
COPY --from=model-downloader --chown=teachai:teachai /models ./models

# Copy RAG data (1,556 files, 232MB)
COPY --chown=teachai:teachai server/rag_data ./server/rag_data

# Copy configuration and Docker support
COPY --chown=teachai:teachai package.json pnpm-workspace.yaml ./
COPY --chown=teachai:teachai docker ./docker
COPY --chown=teachai:teachai CLAUDE.md ./

RUN chmod +x ./docker/*.sh

# Create necessary directories with proper permissions
RUN mkdir -p \
    ./data \
    ./logs \
    ./models \
    ./backups \
    ./server/simple-rag/data \
    ./cache/embeddings \
    && chown -R teachai:teachai \
        ./data ./logs ./models ./backups \
        ./server ./cache

# Set environment variables for complete self-hosted deployment
ENV NODE_ENV=production
ENV PORT=3001
ENV WEB_PORT=3000

# RAG Configuration
ENV RAG_DB_TYPE=sqlite-vss
ENV RAG_SQLITE_PATH=/app/data/vectors.db
ENV RAG_DATA_DIR=/app/server/rag_data/chunks
ENV RAG_BACKUP_DIR=/app/backups

# Embedding Configuration  
ENV EMBEDDING_MODEL_PATH=/app/models
ENV EMBEDDING_PROFILE=balanced
ENV EMBEDDING_CACHE_DIR=/app/cache/embeddings
ENV USE_LOCAL_EMBEDDINGS=true

# Resource optimization for 8GB RAM
ENV NODE_OPTIONS="--max-old-space-size=4096"
ENV UV_THREADPOOL_SIZE=4
ENV PYTORCH_DISABLE_CUDA=1

# Auto-initialize RAG system on first run
ENV INIT_LOAD_RAG=true
ENV RAG_AUTO_SETUP=true

# Switch to non-root user
USER teachai

# Expose ports
EXPOSE 3000 3001

# Health check for complete system
HEALTHCHECK --interval=30s --timeout=15s --start-period=120s --retries=3 \
    CMD ./docker/healthcheck.sh

# Initialize and start
ENTRYPOINT ["./docker/entrypoint.sh"]
CMD ["start"]