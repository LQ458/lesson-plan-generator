# Technology Empowering Education: Assessment of AI-Generated Lesson Plans for Self-Study Assistance in Resource-Limited Areas (Bijie, Guizhou) and Exploration of Localized Applications

## I. Research Background and Objectives

### Background
There exists an imbalance in educational resources between urban and rural areas, as well as between eastern and western regions in China. Bijie, as a prefecture-level city in Guizhou Province, may have relatively weak teaching staff and limited access to teaching resources (especially high-quality electronic devices and network resources) in some rural schools. Meanwhile, AI technology applications in education are emerging, but empirical research on their effectiveness in resource-limited areas is insufficient.

### Research Objectives
1. **Empirical Assessment**: Through controlled experiments, scientifically evaluate the effectiveness differences between AI-generated lesson plans and traditional lesson plans in assisting student self-study
2. **Difficulty Insights**: Deeply understand the specific difficulties local students face in using electronic devices and accessing resources, providing basis for technology localization
3. **Needs Discovery**: Through field observations, gain insights into students' real learning habits, methods, and potential needs for new learning tools
4. **Product Prototype**: Based on research findings, design a self-study platform or manual prototype more suitable for students in Bijie (and similar areas) with low resource dependency

## II. Core Research Content and Methods

This project will adopt a **mixed research approach** (quantitative + qualitative), divided into four phases:

### Phase I: Preparation and Pre-research (1-2 weeks)

**Main Tasks:**
1. **Contact Research Sites**: Establish contact with 1-2 target primary and secondary schools in Bijie, obtaining participation permission from school administration, teachers, and students
2. **Ethics Preparation**: Prepare informed consent forms, clearly explaining research purposes, procedures, privacy protection measures, and their rights to schools, teachers, students, and parents
3. **Material Preparation**: Finalize AI lesson plans and traditional lesson plans for testing (content and difficulty must be strictly matched); prepare pre-test/post-test questionnaires, interview outlines, observation record forms, and other tools
4. **Equipment Inspection**: Conduct on-site inspection of school computer rooms, availability of students' own devices, and network conditions, providing realistic basis for experimental design

### Phase II: Quantitative Research - Controlled Experiments

**Core Measurement Dimensions and Indicators:**

We will measure "effectiveness" from four dimensions:
1. Learning outcomes and efficiency
2. Behavioral engagement
3. Emotional/cognitive engagement
4. Subjective experience and satisfaction

#### 1. Learning Outcomes and Efficiency

**Immediate Learning Achievement:**
- **Indicator**: Post-test standardized test scores
- **Measurement Method**: Tests conducted immediately after the learning phase, including basic knowledge questions and application questions
- **Analysis**: Use independent samples t-test to compare post-test average scores between AI group and traditional group, while using analysis of covariance with pre-test scores as covariates

**Learning Efficiency:**
- **Indicator**: Time required to complete specific learning tasks
- **Measurement Method**: Record the time each student spends from starting self-study to completing all learning materials
- **Analysis**: Use t-test to compare average learning time between the two groups

**Knowledge Retention:**
- **Indicator**: Delayed post-test scores
- **Measurement Method**: 1-2 weeks after the first post-test, conduct another test using a questionnaire similar in difficulty and content to the post-test
- **Analysis**: Compare delayed post-test scores between groups, evaluating which lesson plan brings more lasting knowledge memory

#### 2. Behavioral Engagement

**Task Persistence:**
- **Indicator**: Proportion of students who actively give up or fail to complete learning tasks
- **Measurement Method**: Record how many students in each group stop before completing all materials
- **Analysis**: Compare abandonment rates between groups (can use chi-square test)

**Interaction Frequency:**
- **Indicator**: Number of times actively asking questions or seeking help
- **Measurement Method**: In on-site observation record forms, record the number of times each student asks content-related questions to researchers or teachers
- **Analysis**: Compare average question frequency between groups (t-test)

**Note-taking Behavior:**
- **Indicator**: Proportion of students taking notes and word count/volume of notes
- **Measurement Method**: Observe and record how many students in each group take notes, collect students' note papers for word count or content analysis
- **Analysis**: Compare note-taking behavior differences between groups

#### 3. Emotional and Cognitive Engagement

**Cognitive Load:**
- **Indicator**: NASA-TLX cognitive load scale (simplified version) scores
- **Measurement Method**: After learning, have students answer several questions on a 9-point scale
- **Analysis**: Compare total cognitive load scores between groups, lower scores indicate smoother learning process

**Situational Interest:**
- **Indicator**: Immediate interest level
- **Measurement Method**: After learning, directly ask: "How interesting do you find the learning content just covered?" (using 1-5 point Likert scale)
- **Analysis**: Compare average interest scores between groups

#### 4. Subjective Experience and Satisfaction

**Lesson Plan Satisfaction Questionnaire:**
- **Indicator**: Satisfaction scale scores
- **Measurement Method**: Use a questionnaire with multiple items, having students evaluate the clarity, usefulness, attractiveness, etc. of lesson plans
- **Analysis**: Calculate average scores for each dimension and conduct between-group comparisons

**Preference Choice:**
- **Indicator**: Future usage intention
- **Measurement Method**: At the end of the experiment, directly ask students which material they prefer to use in the future
- **Analysis**: Count and compare proportions of students choosing different lesson plans (chi-square test)

**Data Collection Tools:**
1. Pre-test/post-test/delayed post-test questionnaires: Carefully designed standardized questionnaires
2. Observation record forms: Structured forms for recording behavioral indicators
3. Immediate feedback scales: NASA-TLX simplified scale and situational interest single-question scale
4. Satisfaction questionnaire: Short questionnaire with 5-7 items
5. Timer: For recording each student's learning time

### Phase III: Qualitative Research - Field Observations and In-depth Interviews

**Core Objectives:**
1. **Deep Understanding of Context**: Reveal reasons behind numbers, explaining causes of experimental results
2. **Discover Unexpected Insights**: Capture subtle behaviors and attitudes that quantitative questionnaires cannot cover
3. **Insight into Real Needs**: Provide first-hand inspiration for designing truly "usable and user-friendly" localized self-study solutions

**Preparation Work:**
1. **Ethics First**: Prepare and sign informed consent forms, clearly informing research purposes, data usage, privacy protection measures, and right to withdraw at any time
2. **Tool Preparation**: Observation record forms, interview outlines, notebooks, pens, voice recorders (with permission), cameras (with permission)
3. **Clear Identity**: Inform that the role is "learner" and "observer," not "evaluator," to reduce "Hawthorne effect"

#### Participatory Observation Guidelines

**Observation Focus**: Behavior, interaction, environment, emotional responses

**Observation Content Checklist:**

1. **Learning Habits and Processes:**
   - Pre-class/self-study start: How do they prepare? Do they actively preview? How do they obtain materials?
   - Note-taking methods: Do they copy from blackboard/screen, or have their own methods (like underlining, drawing, summarizing)? Where do they write notes (dedicated notebooks, books, scrap paper)?
   - When encountering difficulties: What's the first reaction? (staring blankly, flipping through books, asking desk mates, asking teachers, giving up directly) How do they express questions?
   - Tool usage: Besides textbooks, what else do they use? Reference books? Dictionaries? Phones? How do they use them?

2. **Reactions to Experimental Materials (AI vs. Traditional):**
   - Confusion points: Record specifically which knowledge point or sentence caused confusion
   - Excitement points/interest points: Record what content sparked interest
   - Operational difficulties: Observe if they get stuck on interface navigation? Do they get distracted due to device lag or low battery?

3. **Social Interaction Patterns:**
   - Is learning isolated or collaborative? How do they discuss problems?
   - Student-teacher interaction patterns

4. **Environment and Context:**
   - Classroom lighting, noise, desk and chair layout
   - Is electronic device charging convenient? How is network signal?

**Observation Methods:**
- "Umbrella" observation: First conduct overall scanning to understand overall class atmosphere
- "Focus" observation: Select 3-5 representative students for 15-minute interval tracking records
- Momentary sampling: Every 5 minutes, quickly record current moment behaviors of specific students

**Observation Record Form Template:**

| Time | Observed Behavior/Event (Objective Description) | My Interpretation/Questions (Subjective Thinking) | Possible Corresponding Research Questions |
|------|------------------------------------------------|--------------------------------------------------|-------------------------------------------|
| 14:05 | Student A saw the animated illustration in the lesson plan, nudged Student B with elbow, pointed at screen, whispered "Wow, this is cool" | Dynamic visual content effectively stimulates interest. Traditional lesson plans lack this element | AI lesson plans' advantages in boosting interest? |
| 14:15 | Student C stayed at page 3 exercises for over 5 minutes, constantly erasing and rewriting, finally sighed and put down pen | This question might be too difficult, or explanation insufficient. Clear frustration. Need to ask during interview | Is AI lesson plan's difficulty gradient setting reasonable? |
| 14:30 | Over half the students tried clicking on images in printed lesson plan, seemingly expecting interactive effects | Students are already accustomed to digital media interactivity, paper materials may seem "rigid" | How to combine offline and online forms? |

#### Semi-structured Interview Guidelines

**Core Principles**: Ask more open-ended "why" and "how" questions, avoid leading questions, create relaxed, trusting atmosphere

**Student Interview Outline:**

1. **Background and Resource Access:**
   - "Do you have computers or tablets at home that can be used for learning? Who mainly uses them?"
   - "What do you usually do with your phone? Do you use it to look up study materials? How?"
   - "When you encounter homework problems, besides asking teachers and classmates, what else do you do?"

2. **Learning Experience and Difficulties:**
   - "For today's new (AI) material, which part did you find most difficult? Why?"
   - "Was there any part that made you think 'Oh, that's how it is' or found interesting?"
   - "Compared to lesson plans teachers usually give, what do you think is the biggest difference? Which do you prefer? Why?"

3. **Imagination and Preferences:**
   - "If you were to design a tool to help you self-study, what would you want it to look like?"
   - "What functions would you hope it has?"

**Teacher Interview Outline:**

1. **Teaching Practice:**
   - "How do you usually prepare lessons and lesson plans/study guides? What resources do you typically reference?"
   - "In your view, what are the biggest difficulties students face in self-study?"

2. **Technology Attitudes and Challenges:**
   - "How do you view AI technology assisting teaching? What expectations and concerns do you have?"
   - "What practical difficulties do you encounter using digital technology in teaching?"

3. **Feedback on Experiments:**
   - "You observed students using these materials, what impressed you most?"
   - "Where do you think AI-generated lesson plans might really help you? Where might not be very applicable?"

#### Artifact Collection and Analysis

**Collection Content**: Notes, draft papers, homework produced by students during experiments

**Analysis Methods**:
- **Content**: What did they record? Key points, example questions, or their own summaries?
- **Structure**: Are notes organized? Can they reflect their thinking logic?
- **Interaction with Materials**: Did they do extensive marking, annotation on materials?

**Daily Field Reflection**:
After each day, spend 30 minutes answering these questions:
1. What was the biggest surprise today?
2. Were my main assumptions challenged?
3. Did I overlook any group or perspective?
4. How should I adjust tomorrow's observations and interviews?

### Phase IV: Comprehensive Analysis and Product Design (1-2 weeks after research)

**Main Tasks**: Self-study manual & Platform/website/manual prototype

**Methods**:
1. **Data Triangulation**: Cross-validate quantitative data with qualitative data for comprehensive analysis, explaining "why" such results were produced
2. **Design Thinking Workshop**: Invite some students and teachers to brainstorm what ideal self-study tools should look like based on discovered needs and difficulties
3. **Output Results**:
   - **Field Research Report**: Detailed elaboration of research findings, conclusions, and recommendations
   - **"Low Resource Dependency" Self-study Manual Prototype**: Imitate Khan Academy style but fully consider Bijie's actual situation:
     - Offline priority: Content can be printed into booklets or support offline download in mobile APP form
     - Lightweight: Compressed images and videos to reduce traffic consumption
     - Extremely simple operation: Clean interface, clear steps, lowering usage threshold
     - Localized cases: Integrate local student-familiar contexts and examples in example questions and explanations
   - **Localization Recommendations**: Analyze feasibility of directly transplanting high-end platforms, propose how to take their essence while removing dross, achieving dimensional reduction application strategies

## III. Timeline

| Week | Phase | Main Tasks |
|------|-------|------------|
| Week 1 | Preparation and Pre-research | Contact schools, obtain permission, prepare materials, ethics review |
| Week 2 | Quantitative Experiments | Implement pre-test, intervention, post-test, collect quantitative data |
| Week 3 | Field Observations | Conduct classroom observations, carry out student/teacher interviews |
| Week 4 | Data Analysis | Data organization, statistical analysis, interview transcription |
| Week 5-6 | Report Writing and Design | Synthesize all data, write report, design self-study manual prototype |

## IV. Expected Outcomes

1. **Academic Outcomes**: A complete field research report that can be used for course assignments, academic conferences, or journal publications
2. **Practical Outcomes**: A field-validated "AI-assisted lesson plan" application model and localized self-study manual prototype applicable to resource-limited areas
3. **Social Value**: Provide empirical evidence and implementation references for educational technology companies, non-profit organizations, and government departments promoting educational technology in similar areas

## V. Potential Challenges and Responses

**Challenge 1: Difficulty in School Access**
- **Response**: Connect through local education bureaus, Communist Youth League, university teaching support associations, emphasizing research's public welfare nature and value to schools

**Challenge 2: Extremely Poor Electronic Devices and Network Conditions**
- **Response**: Prepare offline solutions as backup (such as printed lesson plans, videos stored on local computers). This is exactly the "difficulty" that research needs to focus on

**Challenge 3: Low Student/Teacher Participation**
- **Response**: Design interesting learning content and interactive sessions; prepare some small gifts (stationery, etc.) as thanks

**Challenge 4: Cultural Differences and Understanding Deviations**
- **Response**: Find a local person as guide or translator; maintain open and humble learning attitude, avoid preconceptions

## VI. Required Resources and Budget

**Human Resources**: 1-2 researchers, possible local coordinator or assistant

**Material Resources**: Test questionnaires, interview outlines, notebooks, voice recorders (with permission), thank you gifts

**Technical Resources**: Laptops, electronic devices for testing (if schools cannot provide), statistical analysis software (such as SPSS, Python, R)

**Budget**: Including transportation, accommodation, material printing, gifts, possible service fees, etc.
